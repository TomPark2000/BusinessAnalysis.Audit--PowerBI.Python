{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c2162e",
   "metadata": {},
   "source": [
    "# Dummy Data for Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f49f2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Client ID Client Name Country State  Money ($M) Issue ID  Issue Date  \\\n",
      "0          1    Client 1      US  Ohio      654.52  Issue 1  05/31/2023   \n",
      "1          1    Client 1      US  Ohio      654.52  Issue 2  03/24/2024   \n",
      "2          1    Client 1      US  Ohio      654.52  Issue 3  05/13/2024   \n",
      "3          1    Client 1      US  Ohio      654.52  Issue 4  11/05/2023   \n",
      "4          1    Client 1      US  Ohio      654.52  Issue 5  12/20/2022   \n",
      "\n",
      "   Status  Issue Value      Type  \n",
      "0    Open           12  Method 1  \n",
      "1  Closed           88  Method 2  \n",
      "2  Closed           77  Method 2  \n",
      "3    Open           66  Method 2  \n",
      "4    Open           54  Method 2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of unique clients and total issues\n",
    "num_clients = 1200\n",
    "total_issues = 10000\n",
    "\n",
    "# Countries and their distribution\n",
    "primary_countries = ['US', 'UK', 'Canada']\n",
    "additional_countries = ['Germany', 'France', 'Australia', 'Japan', 'India', 'Brazil', 'South Africa']\n",
    "all_countries = primary_countries + additional_countries\n",
    "\n",
    "\n",
    "# Distribution: 50% US, 20% UK, 15% Canada, 15% for all other countries evenly\n",
    "#country_distribution\n",
    "raw_distribution = [0.5, 0.2, 0.15] + [(0.15 / len(additional_countries)) for _ in additional_countries]\n",
    "normalized_distribution = np.array(raw_distribution) / np.sum(raw_distribution)\n",
    "\n",
    "# Sample countries for clients\n",
    "client_countries = np.random.choice(all_countries, num_clients, p=normalized_distribution)\n",
    "\n",
    "# Country-specific states/provinces\n",
    "country_states = {\n",
    "    'US': ['California', 'Texas', 'Florida', 'New York', 'Illinois', 'Pennsylvania', 'Ohio', 'Georgia', 'North Carolina', 'Michigan'],\n",
    "    'Canada': ['Ontario', 'Quebec', 'British Columbia', 'Alberta', 'Manitoba', 'Saskatchewan', 'Nova Scotia', 'New Brunswick', 'Newfoundland and Labrador', 'Prince Edward Island'],\n",
    "    'UK': ['England', 'Scotland', 'Wales', 'Northern Ireland'],\n",
    "    'Germany': ['Bavaria', 'Berlin', 'Hamburg'],\n",
    "    'France': ['Île-de-France', 'Provence-Alpes-Côte d\\'Azur'],\n",
    "    'Australia': ['New South Wales', 'Victoria'],\n",
    "    'Japan': ['Tokyo', 'Osaka'],\n",
    "    'India': ['Maharashtra', 'Delhi'],\n",
    "    'Brazil': ['São Paulo', 'Rio de Janeiro'],\n",
    "    'South Africa': ['Gauteng', 'Western Cape'],\n",
    "}\n",
    "\n",
    "# Assign states based on country\n",
    "def assign_state(country):\n",
    "    states = country_states.get(country, ['Generic State'])\n",
    "    return np.random.choice(states)\n",
    "\n",
    "client_states = [assign_state(country) for country in client_countries]\n",
    "\n",
    "# Generate other client data\n",
    "client_ids = range(1, num_clients + 1)\n",
    "client_names = [f\"Client {i}\" for i in client_ids]\n",
    "money = np.random.uniform(1, 1000, num_clients).round(2)  # MONEY for each client\n",
    "\n",
    "# DataFrame\n",
    "clients_df = pd.DataFrame({\n",
    "    'Client ID': client_ids,\n",
    "    'Client Name': client_names,\n",
    "    'Country': client_countries,\n",
    "    'State': client_states,\n",
    "    'Money ($M)': money,\n",
    "})\n",
    "\n",
    "\n",
    "# Date generation and concatenation segment\n",
    "dates_2022 = pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\").strftime(\"%m/%d/%Y\")\n",
    "dates_2023 = pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\").strftime(\"%m/%d/%Y\")\n",
    "dates_2024_series = pd.Series(pd.date_range(start=\"2024-01-01\", end=\"2024-12-31\").strftime(\"%m/%d/%Y\"))\n",
    "dates_2025 = pd.date_range(start=\"2025-01-01\", end=\"2025-12-31\").strftime(\"%m/%d/%Y\")\n",
    "dates_2026 = pd.date_range(start=\"2026-01-01\", end=\"2026-12-31\").strftime(\"%m/%d/%Y\")\n",
    "\n",
    "# Duplicate 2024 dates to increase their representation\n",
    "dates_2024_duplicated = pd.concat([dates_2024_series, dates_2024_series])\n",
    "\n",
    "# Combine all dates into a single Series and shuffle\n",
    "all_dates = pd.concat([pd.Series(dates_2022), pd.Series(dates_2023), dates_2024_duplicated, pd.Series(dates_2025), pd.Series(dates_2026)]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Select the first 10,000 dates\n",
    "final_dates = all_dates[:10000].tolist()\n",
    "\n",
    "\n",
    "# Statuses with most closed\n",
    "statuses = np.random.choice([\"Open\", \"Closed\"], total_issues, p=[0.35, 0.65])\n",
    "\n",
    "\n",
    "# Generate 10,000 total issues\n",
    "issues_per_client = np.random.multinomial(total_issues, [1/num_clients]*num_clients)\n",
    "\n",
    "issues_list = []\n",
    "issue_counter = 0  # Counter to assign dates and statuses sequentially\n",
    "\n",
    "\n",
    "for client_index, num_issues in enumerate(issues_per_client, start=1):\n",
    "    for issue in range(num_issues):\n",
    "        client_row = clients_df.loc[clients_df['Client ID'] == client_index].copy()\n",
    "        client_row['Issue ID'] = f'Issue {issue_counter + 1}'\n",
    "        client_row['Issue Date'] = dates[issue_counter]\n",
    "        client_row['Status'] = statuses[issue_counter]\n",
    "        client_row['Issue Value'] = np.random.randint(1, 100)  # Example issue-specific detail\n",
    "        issues_list.append(client_row)\n",
    "        issue_counter += 1  # Increment counter for each issue\n",
    "\n",
    "\n",
    "# Combine all issues into a single DataFrame\n",
    "all_issues_df = pd.concat(issues_list, ignore_index=True)\n",
    "\n",
    "# Generate 'Type' for each issue based on specified distribution\n",
    "types = ['Method 1', 'Method 2', 'Method 3']\n",
    "type_distribution = [0.45, 0.45, 0.10]\n",
    "investor_types = np.random.choice(types, total_issues, p=type_distribution)\n",
    "\n",
    "# Add 'Type' column to all_issues_df\n",
    "all_issues_df['Type'] = investor_types\n",
    "\n",
    "# Now all_issues_df includes 'Issue Date', 'Status', and 'Type' columns\n",
    "print(all_issues_df.head())\n",
    "\n",
    "\n",
    "all_issues_df.to_csv(r'.....', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
